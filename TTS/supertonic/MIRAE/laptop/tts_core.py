# tts_core.py
import os
import time
import queue
import threading
import platform
import subprocess
import re
from typing import Optional

from scipy.io import wavfile
from tts_engine import TTSEngine
import numpy as np


def split_text(text: str, first_free: bool = True, min_len: int = 40):
    """
    - ì²« ì²­í¬: ê¸¸ì´ ì œí•œ ì—†ì´, ì²˜ìŒ ë§Œë‚˜ëŠ” ë¬¸ì¥ë¶€í˜¸ì—ì„œ ì¦‰ì‹œ ë¶„í• 
    - ì´í›„ ì²­í¬: ìµœì†Œ min_len(ê¸°ë³¸ 40ì) ì´í›„, ë¬¸ì¥ë¶€í˜¸ì—ì„œë§Œ ë¶„í• 
    """

    seps = set(".,?!ï¼Œã€‚ï¼ï¼Ÿ\n")
    chunks = []
    buf = ""

    it = iter(text)

    # 1ï¸âƒ£ ì²« ì²­í¬ (ë”œë ˆì´ ìµœì†Œí™”)
    if first_free:
        for ch in it:
            buf += ch
            if ch in seps:
                chunks.append(buf)
                buf = ""
                break

    # 2ï¸âƒ£ ì´í›„ ì²­í¬ (ê¸°ì¡´ ê·œì¹™: 40ì ì´í›„ ë¬¸ì¥ë¶€í˜¸)
    for ch in it:
        buf += ch

        if len(buf) < min_len:
            continue

        if ch in seps:
            chunks.append(buf)
            buf = ""

    if buf.strip():
        chunks.append(buf)

    return chunks



class TTSService:
    """
    - ì„œë²„ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì‹œ ONNX ì—”ì§„ì„ 1íšŒ ë¡œë”©í•˜ê³  ì¬ì‚¬ìš©
    - speak_async()ë¡œ ë°±ê·¸ë¼ìš´ë“œ í•©ì„±/ì¬ìƒ ì‹¤í–‰
    - stop() í˜¸ì¶œ ì‹œ, ë‹¤ìŒ ì²­í¬ë¶€í„° ì¬ìƒ/ìƒì„±ì„ ì¤‘ë‹¨(í˜‘ì¡°ì  ì·¨ì†Œ)
    """

    def __init__(self):
        # laptop í´ë” ê¸°ì¤€ìœ¼ë¡œ BASE_DIR = MIRAE (.., ..)
        self.base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))

        self.engine = TTSEngine(
            onnx_dir=os.path.join(self.base_dir, "assets", "onnx"),
            voice_style_path=os.path.join(self.base_dir, "assets", "voice_styles", "M1.json"),
        )

        self.filler_wav = os.path.join(self.base_dir, "assets", "fillers", "um.wav")

        # ì„ì‹œ wav ì²­í¬ ì €ì¥ í´ë”
        self.temp_dir = os.path.join(os.path.dirname(__file__), "..", "_tmp_audio")
        os.makedirs(self.temp_dir, exist_ok=True)

        # ì‹¤í–‰ ì œì–´
        self._stop_event = threading.Event()
        self._worker_thread: Optional[threading.Thread] = None
        self._lock = threading.Lock()

    # -----------------------------
    # Public API
    # -----------------------------
    def is_running(self) -> bool:
        t = self._worker_thread
        return t is not None and t.is_alive()

    def stop(self) -> None:
        """í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì¬ìƒ/ìƒì„±ì„ ì¤‘ë‹¨ ìš”ì²­."""
        self._stop_event.set()

    def speak_async(self, text: str) -> None:
        """
        - ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ stop() ìš”ì²­ í›„ ìƒˆ ì‘ì—… ì‹œì‘
        - ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ìˆ˜í–‰ (FastAPI ìš”ì²­ì„ ë§‰ì§€ ì•ŠìŒ)
        """
        text = (text or "").strip()
        if not text:
            return

        with self._lock:
            # ê¸°ì¡´ ì‹¤í–‰ ì¤‘ì´ë©´ ì¤‘ë‹¨ ìš”ì²­
            if self.is_running():
                self._stop_event.set()

            # ìƒˆ ì‘ì—… ì¤€ë¹„
            self._stop_event.clear()
            self._worker_thread = threading.Thread(
                target=self._run_pipeline,
                args=(text,),
                daemon=True
            )
            self._worker_thread.start()

    # -----------------------------
    # Internal helpers
    # -----------------------------
    def _play_wav(self, path: str) -> None:
        system = platform.system()
        try:
            if system == "Windows":
                import winsound
                winsound.PlaySound(path, winsound.SND_FILENAME)
            elif system == "Darwin":
                subprocess.run(["afplay", path], check=False)
            else:
                subprocess.run(["aplay", path], check=False)
        except Exception as e:
            print(f"âš ï¸ ì¬ìƒ ì‹¤íŒ¨: {e}")

    def _play_filler(self, program_start: float) -> None:
        if self._stop_event.is_set():
            return
        if not os.path.exists(self.filler_wav):
            print("âš ï¸ filler ìŒì„± íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        latency = time.time() - program_start
        print("ğŸ§ filler ì¬ìƒ ì‹œì‘: ìŒ...")
        print(f"â±ï¸ filler ì¬ìƒ ì‹œì‘ê¹Œì§€: {latency:.3f}ì´ˆ")
        self._play_wav(self.filler_wav)

    def _producer(self, text: str, audio_q: queue.Queue) -> None:
        print("\n=== TTS GENERATION START ===")

        chunks = split_text(text, first_free=True, min_len=40)

        for i, chunk in enumerate(chunks, start=1):
            if self._stop_event.is_set():
                break

            preview = chunk.replace("\n", " ")[:50]
            print(f"[GEN {i:02d}] {preview}")

            wav_parts = []
            start = time.time()

            for wav, _ in self.engine.synthesize_streaming(chunk):
                if self._stop_event.is_set():
                    break
                wav_parts.append(wav)

            if not wav_parts:
                continue

            elapsed = time.time() - start

            # ğŸ”¥ ê° GENë§ˆë‹¤ í•œ ë²ˆì”©ë§Œ ì¶œë ¥
            print(f"   âœ… ì™„ë£Œ ({elapsed:.2f}ì´ˆ, {len(chunk)}ì)")

            merged = np.concatenate(wav_parts, axis=0)
            temp_file = os.path.join(self.temp_dir, f"chunk_{i}.wav")
            wavfile.write(temp_file, self.engine.sample_rate, merged)
            audio_q.put((i, temp_file))

        audio_q.put(None)
        print("=== GENERATION END ===\n")

    def _consumer(self, audio_q: queue.Queue) -> None:
        print("=== PLAYBACK START ===")

        while True:
            item = audio_q.get()
            if item is None:
                print("=== PLAYBACK END ===")
                break

            if self._stop_event.is_set():
                idx, audio_file = item
                if os.path.exists(audio_file):
                    try:
                        os.remove(audio_file)
                    except:
                        pass

                # í ë¹„ìš°ê¸°
                while True:
                    rest = audio_q.get()
                    if rest is None:
                        break
                    _, f = rest
                    if os.path.exists(f):
                        try:
                            os.remove(f)
                        except:
                            pass
                break  # â† ì´ breakëŠ” try ë¸”ë¡ ë°”ê¹¥

            idx, audio_file = item
            print(f"[PLAY {idx:02d}]")
            self._play_wav(audio_file)

            if os.path.exists(audio_file):
                try:
                    os.remove(audio_file)
                except:
                    pass

    def _run_pipeline(self, text: str) -> None:
        program_start = time.time()
        print(f"ğŸ“ í…ìŠ¤íŠ¸ ë¡œë“œ ì™„ë£Œ ({len(text)}ì)")
        print("=" * 60)

        audio_q: queue.Queue = queue.Queue(maxsize=3)

        # fillerëŠ” ì¦‰ì‹œ ì¬ìƒ(ë³„ë„ ìŠ¤ë ˆë“œ)
        threading.Thread(
            target=self._play_filler,
            args=(program_start,),
            daemon=True
        ).start()

        # producer / consumer
        producer_t = threading.Thread(
            target=self._producer,
            args=(text, audio_q),
            daemon=True
        )
        consumer_t = threading.Thread(
            target=self._consumer,
            args=(audio_q,),
            daemon=True
        )

        producer_t.start()
        consumer_t.start()

        producer_t.join()
        consumer_t.join()

        print("=" * 60)
        if self._stop_event.is_set():
            print("ğŸ›‘ ì¤‘ë‹¨ ìš”ì²­ìœ¼ë¡œ ì¢…ë£Œ")
        else:
            print("ğŸ‰ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
